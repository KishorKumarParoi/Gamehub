# ğŸ“š Complete Kubernetes Learning Guide: Beginner to Advanced

I'll create a comprehensive guide covering everything from basics to advanced concepts, plus the differences between Kubernetes deployment tools.

---

## ğŸ¯ Table of Contents

1. **Kubernetes Fundamentals**
2. **Core Concepts & Objects**
3. **Deployment Tools (kind vs Minikube vs kops vs kubeadm)**
4. **Networking**
5. **Storage**
6. **Advanced Topics**
7. **Best Practices**

---

# ğŸ“– PART 1: Kubernetes Fundamentals

## ğŸ—ï¸ What is Kubernetes?

```
Kubernetes = Container Orchestration Platform

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Kubernetes                              â”‚
â”‚  Automatically manages containerized applications        â”‚
â”‚                                                          â”‚
â”‚  Features:                                               â”‚
â”‚  â”œâ”€ Container deployment                                â”‚
â”‚  â”œâ”€ Scaling                                             â”‚
â”‚  â”œâ”€ Networking                                          â”‚
â”‚  â”œâ”€ Storage management                                  â”‚
â”‚  â”œâ”€ Self-healing                                        â”‚
â”‚  â”œâ”€ Load balancing                                      â”‚
â”‚  â””â”€ Rolling updates                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Kubernetes?

```
Problems it solves:

1. Container Management
   â”œâ”€ Run 1000s of containers
   â”œâ”€ Automatically schedule them
   â””â”€ Keep them running

2. High Availability
   â”œâ”€ Self-healing (restart failed pods)
   â”œâ”€ Multi-replica deployments
   â””â”€ Health checks

3. Resource Optimization
   â”œâ”€ Bin packing (efficient resource use)
   â”œâ”€ CPU/Memory limits
   â””â”€ Auto-scaling based on demand

4. Rolling Updates
   â”œâ”€ Zero-downtime deployments
   â”œâ”€ Automatic rollback
   â””â”€ Canary deployments

5. Networking
   â”œâ”€ Service discovery
   â”œâ”€ Load balancing
   â””â”€ Network policies
```

---

## ğŸ›ï¸ Kubernetes Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  KUBERNETES CLUSTER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              CONTROL PLANE (Master)                     â”‚ â”‚
â”‚  â”‚  (Manages the cluster)                                  â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚  â”‚  â”‚  API Server    â”‚  â”‚  etcd (Database)              â”‚ â”‚
â”‚  â”‚  â”‚ (REST API)     â”‚  â”‚ (Cluster state)               â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚  â”‚  â”‚  Scheduler     â”‚  â”‚  Controller    â”‚                â”‚ â”‚
â”‚  â”‚  â”‚ (Pod placement)â”‚  â”‚  Manager       â”‚                â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ (Reconciliation)               â”‚ â”‚
â”‚  â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚                                  â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚        â”‚                  â”‚                  â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   WORKER 1 â”‚  â”‚   WORKER 2     â”‚  â”‚   WORKER N     â”‚    â”‚
â”‚  â”‚  (Node)    â”‚  â”‚   (Node)       â”‚  â”‚   (Node)       â”‚    â”‚
â”‚  â”‚            â”‚  â”‚                â”‚  â”‚                â”‚    â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚ â”‚ kubeletâ”‚ â”‚  â”‚ â”‚ kubeletâ”‚     â”‚  â”‚ â”‚ kubeletâ”‚     â”‚    â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚            â”‚  â”‚                â”‚  â”‚                â”‚    â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚ â”‚ Pod 1  â”‚ â”‚  â”‚ â”‚ Pod 3  â”‚     â”‚  â”‚ â”‚ Pod 5  â”‚     â”‚    â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â”‚            â”‚  â”‚                â”‚  â”‚                â”‚    â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”‚
â”‚  â”‚ â”‚ Pod 2  â”‚ â”‚  â”‚ â”‚ Pod 4  â”‚     â”‚  â”‚ â”‚ Pod 6  â”‚     â”‚    â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Control Plane Components

| Component | Purpose |
|-----------|---------|
| **API Server** | Central hub, exposes REST API |
| **etcd** | Distributed database storing cluster state |
| **Scheduler** | Assigns pods to nodes |
| **Controller Manager** | Runs controller processes |
| **Cloud Controller Manager** | Integrates with cloud providers |

### Node (Worker) Components

| Component | Purpose |
|-----------|---------|
| **kubelet** | Agent running on each node, manages containers |
| **Container Runtime** | Runs containers (Docker, containerd, etc.) |
| **kube-proxy** | Network proxy, manages networking |

---

# ğŸ§© PART 2: Core Kubernetes Objects & Concepts

## 1ï¸âƒ£ Pod (Basic Unit)

**Pod** = Smallest deployable unit in Kubernetes (like a container, but can have multiple containers)

````yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
  labels:
    app: web
spec:
  containers:
  - name: app
    image: nginx:1.21
    ports:
    - containerPort: 80
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
````

**Key Points:**
- Pods are ephemeral (temporary)
- Usually managed by higher-level objects
- Can have multiple containers (sidecar pattern)

---

## 2ï¸âƒ£ ReplicaSet (Multiple Pods)

**ReplicaSet** = Ensures desired number of pods are running

````yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: web-rs
spec:
  replicas: 3           # Keep 3 pods running
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
````

**How it works:**
```
ReplicaSet with 3 replicas:
â”œâ”€ Pod 1 â”€â”
â”œâ”€ Pod 2  â”œâ”€ All running the same image
â”œâ”€ Pod 3 â”€â”˜

If Pod 1 dies â†’ ReplicaSet creates new Pod 4 automatically
If Pod 1 restarts â†’ ReplicaSet deletes the new Pod 4
```

---

## 3ï¸âƒ£ Deployment (Recommended!)

**Deployment** = ReplicaSet + Rolling Updates + Rollback

````yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
        livenessProbe:          # Keep pod alive
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:         # Ready to receive traffic
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
````

**Why Deployment > ReplicaSet:**
- Rolling updates (gradual rollout)
- Automatic rollback
- Pause/resume deployments
- Revision history

### Rolling Update Example

```
Version 1: 3 pods running
Pod-v1-1, Pod-v1-2, Pod-v1-3

Update to Version 2:
Step 1: Start Pod-v2-1, keep Pod-v1-1, Pod-v1-2, Pod-v1-3
Step 2: Stop Pod-v1-1, start Pod-v2-2
Step 3: Stop Pod-v1-2, start Pod-v2-3
Step 4: Stop Pod-v1-3

Result: 3 pods running (all v2)
â”œâ”€ Pod-v2-1
â”œâ”€ Pod-v2-2
â””â”€ Pod-v2-3

Zero downtime! âœ…
```

---

## 4ï¸âƒ£ Service (Networking)

**Service** = Stable endpoint for pods (load balancer)

### Types of Services

#### A. ClusterIP (Internal Only)

````yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  type: ClusterIP              # Default
  selector:
    app: web
  ports:
  - port: 80                   # Service port
    targetPort: 8080           # Container port
    protocol: TCP
````

```
Access: http://web-service:80 (only from inside cluster)
Use case: Internal communication between pods
```

#### B. NodePort (External Access)

````yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  type: NodePort
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080
    nodePort: 30007            # Access via any node:30007
````

```
Access: http://<node-ip>:30007 (from outside cluster)
Use case: Development, testing
Port range: 30000-32767
```

#### C. LoadBalancer (Cloud Load Balancer)

````yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080
````

```
Access: http://<external-ip>:80 (from anywhere)
External IP: Assigned by cloud provider (AWS, GCP, Azure)
Use case: Production services
```

---

## 5ï¸âƒ£ Ingress (HTTP/HTTPS Routing)

**Ingress** = HTTP/HTTPS router to multiple services

````yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
spec:
  ingressClassName: nginx
  rules:
  - host: myapp.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 8080
      - path: /web
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80
  - host: admin.myapp.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: admin-service
            port:
              number: 3000
````

```
Routing Logic:
myapp.com/api       â†’ api-service:8080
myapp.com/web       â†’ web-service:80
admin.myapp.com     â†’ admin-service:3000
```

---

## 6ï¸âƒ£ ConfigMap (Configuration)

**ConfigMap** = Store non-sensitive configuration data

````yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  DATABASE_HOST: postgres.default.svc.cluster.local
  DATABASE_PORT: "5432"
  LOG_LEVEL: info
  APP_ENV: production
````

**Usage in Pod:**

````yaml
spec:
  containers:
  - name: app
    image: myapp:1.0
    env:
    - name: DATABASE_HOST
      valueFrom:
        configMapKeyRef:
          name: app-config
          key: DATABASE_HOST
````

---

## 7ï¸âƒ£ Secret (Sensitive Data)

**Secret** = Store sensitive data (passwords, tokens, etc.)

````yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secret
type: Opaque
data:
  username: dXNlcm5hbWU=       # base64 encoded
  password: cGFzc3dvcmQxMjM=   # base64 encoded
  api-key: YWJjZGVmZ2hpams=
````

**Create from CLI:**

````bash
# Create secret
kubectl create secret generic app-secret \
  --from-literal=username=admin \
  --from-literal=password=secret123

# Create from file
kubectl create secret generic app-secret \
  --from-file=./config.yaml
````

**Usage in Pod:**

````yaml
spec:
  containers:
  - name: app
    env:
    - name: DATABASE_PASSWORD
      valueFrom:
        secretKeyRef:
          name: app-secret
          key: password
````

---

## 8ï¸âƒ£ Namespace (Isolation)

**Namespace** = Virtual cluster within a cluster

```
Kubernetes Cluster
â”œâ”€ Namespace: default
â”‚  â”œâ”€ Pod: web-1
â”‚  â”œâ”€ Pod: web-2
â”‚  â””â”€ Service: web-service
â”‚
â”œâ”€ Namespace: production
â”‚  â”œâ”€ Pod: prod-web-1
â”‚  â”œâ”€ Pod: prod-web-2
â”‚  â””â”€ Service: prod-web-service
â”‚
â””â”€ Namespace: monitoring
   â”œâ”€ Pod: prometheus-1
   â””â”€ Pod: grafana-1
```

**Create Namespace:**

````bash
# Create namespace
kubectl create namespace monitoring

# Create resource in specific namespace
kubectl apply -f deployment.yaml --namespace=monitoring

# Set default namespace
kubectl config set-context --current --namespace=monitoring

# View all namespaces
kubectl get namespaces
````

---

## 9ï¸âƒ£ PersistentVolume (Storage)

**PersistentVolume** = Storage resource in cluster

````yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-storage
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: fast-ssd
  nfs:
    server: 192.168.1.100
    path: "/shared"
````

---

## ğŸ”Ÿ PersistentVolumeClaim (Request Storage)

**PersistentVolumeClaim** = Request for storage

````yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: fast-ssd
````

**Usage in Pod:**

````yaml
spec:
  containers:
  - name: app
    volumeMounts:
    - name: storage
      mountPath: /data
  volumes:
  - name: storage
    persistentVolumeClaim:
      claimName: pvc-storage
````

---

## 1ï¸âƒ£1ï¸âƒ£ StatefulSet (Stateful Apps)

**StatefulSet** = For applications with state (databases, caches)

````yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  replicas: 3
  serviceName: postgres-headless
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:13
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
````

**Key Differences from Deployment:**
- Ordered pod names (postgres-0, postgres-1, postgres-2)
- Sticky network identity
- Ordered scaling
- Data persistence

---

## 1ï¸âƒ£2ï¸âƒ£ DaemonSet (One Pod Per Node)

**DaemonSet** = Ensures pod runs on every node

````yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      containers:
      - name: node-exporter
        image: prom/node-exporter:latest
        ports:
        - containerPort: 9100
````

**Use Cases:**
- Monitoring agents (Prometheus, Datadog)
- Logging agents (Fluentd, Logstash)
- Network plugins
- Security scanning

---

## 1ï¸âƒ£3ï¸âƒ£ Job (Run-Once Tasks)

**Job** = Run container to completion

````yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: data-backup
spec:
  backoffLimit: 3            # Retry 3 times
  parallelism: 2             # Run 2 pods in parallel
  completions: 5             # Need 5 completions
  template:
    spec:
      containers:
      - name: backup
        image: backup-tool:1.0
        command: ["./backup.sh"]
      restartPolicy: OnFailure
````

---

## 1ï¸âƒ£4ï¸âƒ£ CronJob (Scheduled Tasks)

**CronJob** = Run job on schedule (like cron)

````yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: daily-backup
spec:
  schedule: "0 2 * * *"        # 2 AM every day
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: backup-tool:1.0
            command: ["./backup.sh"]
          restartPolicy: OnFailure
````

---

# ğŸš€ PART 3: Kubernetes Deployment Tools

Now let's compare **kind vs Minikube vs kops vs kubeadm**

## Comparison Table

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature      â”‚ kind            â”‚ Minikube     â”‚ kops         â”‚ kubeadm      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Purpose      â”‚ Testing,CI/CD   â”‚ Development  â”‚ Production   â”‚ Any          â”‚
â”‚ Setup Time   â”‚ < 1 minute      â”‚ 2-5 min      â”‚ 10-20 min    â”‚ 15-30 min    â”‚
â”‚ Resources    â”‚ Very low        â”‚ Medium       â”‚ High         â”‚ High         â”‚
â”‚ Nodes        â”‚ 1+ containers   â”‚ 1 VM         â”‚ Multiple AWS â”‚ Multiple     â”‚
â”‚ Cloud        â”‚ Local Docker    â”‚ Local VM     â”‚ AWS only     â”‚ Any cloud    â”‚
â”‚ Persistence  â”‚ âŒ No           â”‚ âœ… Yes       â”‚ âœ… Yes       â”‚ âœ… Yes       â”‚
â”‚ Networking   â”‚ Limited         â”‚ Good         â”‚ Excellent    â”‚ Excellent    â”‚
â”‚ Learning     â”‚ Easy            â”‚ Easy         â”‚ Complex      â”‚ Medium       â”‚
â”‚ Production   â”‚ âŒ No           â”‚ âŒ No        â”‚ âœ… Yes       â”‚ âœ… Yes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ kind (Kubernetes in Docker)

**kind** = Run Kubernetes clusters inside Docker containers

### What is kind?

```
kind (Kubernetes in Docker)
â”œâ”€ Runs K8s clusters in Docker containers
â”œâ”€ No VM needed
â”œâ”€ Perfect for testing & CI/CD
â”œâ”€ Multi-node support
â””â”€ Very lightweight
```

### Installation

````bash
# Install kind
brew install kind

# Verify
kind version
````

### Create Cluster

````bash
# Single node cluster
kind create cluster

# Multi-node cluster
cat > kind-config.yaml << 'EOF'
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
- role: worker
- role: worker
EOF

kind create cluster --config kind-config.yaml

# List clusters
kind get clusters

# Delete cluster
kind delete cluster
````

### Load Local Images

````bash
# Build Docker image
docker build -t myapp:latest .

# Load into kind cluster
kind load docker-image myapp:latest

# Use in deployment
kubectl set image deployment/web myapp=myapp:latest
````

### Pros & Cons

```
âœ… Pros:
â”œâ”€ Fast startup (< 1 minute)
â”œâ”€ Low resource usage
â”œâ”€ No VM needed
â”œâ”€ Perfect for CI/CD
â””â”€ Multi-node support

âŒ Cons:
â”œâ”€ No storage persistence
â”œâ”€ Limited networking features
â”œâ”€ Not for production
â””â”€ Docker dependency
```

### When to Use kind

```
âœ… Use kind when:
â”œâ”€ Testing K8s manifests
â”œâ”€ Local development
â”œâ”€ CI/CD pipelines
â”œâ”€ Educational purposes
â””â”€ Running multiple quick clusters

âŒ Don't use kind when:
â”œâ”€ Need persistent storage
â”œâ”€ Testing stateful apps
â”œâ”€ Need advanced networking
â””â”€ Building production setup
```

---

## ğŸ¯ Minikube (Single-Node VM)

**Minikube** = Single-node Kubernetes cluster in a VM

### What is Minikube?

```
Minikube
â”œâ”€ Runs K8s in a single VM
â”œâ”€ Includes Docker built-in
â”œâ”€ Good for local development
â”œâ”€ Data persistence
â””â”€ Multiple drivers (VirtualBox, Docker, etc)
```

### Installation

````bash
# Install Minikube
brew install minikube

# Install kubectl
brew install kubectl

# Start Minikube
minikube start

# Stop Minikube
minikube stop

# Delete Minikube
minikube delete

# Get Minikube IP
minikube ip
````

### Key Features

````bash
# SSH into Minikube
minikube ssh

# View Minikube dashboard
minikube dashboard

# Access service via browser
minikube service <service-name>

# Tunnel (if supported)
minikube tunnel

# Logs
minikube logs

# Status
minikube status
````

### Configure Minikube

````bash
# Set memory
minikube config set memory 4096

# Set CPU cores
minikube config set cpus 4

# Change driver
minikube start --driver=docker

# Available drivers: virtualbox, docker, hyperkit, vmware, etc
````

### Pros & Cons

```
âœ… Pros:
â”œâ”€ Easy to install
â”œâ”€ Good for local development
â”œâ”€ Data persistence
â”œâ”€ Multiple drivers
â””â”€ Good networking simulation

âŒ Cons:
â”œâ”€ Single node only
â”œâ”€ Higher resource usage than kind
â”œâ”€ Slower startup (2-5 min)
â”œâ”€ Not for production
â””â”€ VM required
```

### When to Use Minikube

```
âœ… Use Minikube when:
â”œâ”€ Learning Kubernetes
â”œâ”€ Local development
â”œâ”€ Testing stateful apps
â”œâ”€ Need persistent storage
â””â”€ Need realistic single-node setup

âŒ Don't use Minikube when:
â”œâ”€ Testing multi-node scenarios
â”œâ”€ Need fast CI/CD
â”œâ”€ Very limited resources
â”œâ”€ Production deployment
â””â”€ Need advanced networking
```

---

## ğŸ¯ kops (Production AWS)

**kops** = Kubernetes Operations (Production-grade for AWS)

### What is kops?

```
kops (Kubernetes Operations)
â”œâ”€ Production-grade Kubernetes
â”œâ”€ AWS-native deployment
â”œâ”€ Full cluster management
â”œâ”€ HA (High Availability)
â”œâ”€ Auto-scaling
â””â”€ Complex but powerful
```

### Installation

````bash
# Install kops
brew install kops

# Install AWS CLI
brew install awscli

# Configure AWS credentials
aws configure

# Verify installation
kops version
````

### Create Cluster

````bash
# Set environment variables
export KOPS_STATE_STORE=s3://my-kops-state-store
export NAME=mycluster.k8s.local

# Create S3 bucket for state
aws s3 mb s3://my-kops-state-store

# Create cluster configuration
kops create cluster \
  --name=$NAME \
  --state=$KOPS_STATE_STORE \
  --zones=us-east-1a,us-east-1b \
  --node-count=3 \
  --node-size=t3.medium \
  --master-size=t3.medium \
  --master-zones=us-east-1a

# Edit cluster (optional)
kops edit cluster --name=$NAME

# Create actual cluster
kops update cluster --name=$NAME --yes

# Validate cluster
kops validate cluster

# Get kubeconfig
kops export kubeconfig --admin
````

### Cluster Management

````bash
# Scale cluster
kops edit ig nodes

# Rolling update
kops rolling-update cluster --name=$NAME --force

# Upgrade Kubernetes version
kops upgrade cluster --name=$NAME
kops update cluster --name=$NAME --yes
kops rolling-update cluster --name=$NAME --force

# Delete cluster
kops delete cluster --name=$NAME --yes
````

### Pros & Cons

```
âœ… Pros:
â”œâ”€ Production-ready
â”œâ”€ HA and multi-AZ support
â”œâ”€ Auto-scaling
â”œâ”€ Full AWS integration
â”œâ”€ Mature and stable
â””â”€ Great cluster management

âŒ Cons:
â”œâ”€ Complex setup
â”œâ”€ AWS-only
â”œâ”€ High cost
â”œâ”€ Steep learning curve
â”œâ”€ State management complexity
â””â”€ Slow to create (10-20 min)
```

### When to Use kops

```
âœ… Use kops when:
â”œâ”€ Production workloads on AWS
â”œâ”€ Need high availability
â”œâ”€ Want managed K8s cluster
â”œâ”€ Running on AWS infrastructure
â””â”€ Need auto-scaling

âŒ Don't use kops when:
â”œâ”€ Multi-cloud deployment
â”œâ”€ GCP or Azure infrastructure
â”œâ”€ Learning Kubernetes
â”œâ”€ Local development
â”œâ”€ Quick prototyping
â””â”€ Don't want AWS vendor lock-in
```

---

## ğŸ¯ kubeadm (Manual Control)

**kubeadm** = Tool to bootstrap Kubernetes cluster

### What is kubeadm?

```
kubeadm
â”œâ”€ Bootstrap Kubernetes manually
â”œâ”€ Works on any cloud/machine
â”œâ”€ More control than kops
â”œâ”€ Multi-cloud support
â”œâ”€ Community standard
â””â”€ Requires more setup
```

### Installation Steps

````bash
# 1. Install on all nodes (control-plane & workers)

# Update package list
sudo apt-get update

# Install Docker
sudo apt-get install -y docker.io

# Install kubeadm, kubectl, kubelet
curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://dl.k8s.io/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubeadm kubectl kubelet

# 2. On Control Plane node only
sudo kubeadm init \
  --pod-network-cidr=10.244.0.0/16 \
  --apiserver-advertise-address=<control-plane-ip>

# 3. Set up kubeconfig
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 4. Install CNI plugin (networking)
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

# 5. On Worker nodes
kubeadm join <control-plane-ip>:6443 \
  --token <token> \
  --discovery-token-ca-cert-hash <hash>

# 6. Verify
kubectl get nodes
````

### Pros & Cons

```
âœ… Pros:
â”œâ”€ Multi-cloud (AWS, GCP, Azure, On-prem)
â”œâ”€ Full control
â”œâ”€ Community standard
â”œâ”€ Production ready
â”œâ”€ Cost effective
â””â”€ Works anywhere

âŒ Cons:
â”œâ”€ Manual setup
â”œâ”€ Complex configuration
â”œâ”€ More troubleshooting needed
â”œâ”€ Steep learning curve
â”œâ”€ No automatic updates
â””â”€ Time-consuming
```

### When to Use kubeadm

```
âœ… Use kubeadm when:
â”œâ”€ Multi-cloud deployment
â”œâ”€ On-premises infrastructure
â”œâ”€ Need maximum control
â”œâ”€ Production workloads
â”œâ”€ GCP or Azure (not AWS)
â””â”€ Want to learn deep K8s

âŒ Don't use kubeadm when:
â”œâ”€ Quick local testing
â”œâ”€ Learning Kubernetes basics
â”œâ”€ Very limited time
â”œâ”€ AWS infrastructure (use kops)
â””â”€ Need managed service
```

---

## ğŸ“Š Decision Matrix

```
Choose based on your scenario:

SCENARIO 1: Learning Kubernetes
â†’ Use: Minikube
  Why: Easy, good simulation, local development

SCENARIO 2: Testing in CI/CD
â†’ Use: kind
  Why: Fast, lightweight, perfect for pipelines

SCENARIO 3: Local Development (Stateful)
â†’ Use: Minikube
  Why: Persistence, good networking, realistic

SCENARIO 4: Production on AWS
â†’ Use: kops or EKS
  Why: Production-ready, HA, fully managed

SCENARIO 5: Production Multi-cloud
â†’ Use: kubeadm
  Why: Works anywhere, full control

SCENARIO 6: Enterprise Cloud
â†’ Use: Managed Services
  Why: EKS (AWS), GKE (GCP), AKS (Azure)
```

---

# ğŸŒ PART 4: Kubernetes Networking

## Network Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Kubernetes Network Model                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  1. Pod-to-Pod Communication                       â”‚
â”‚     â””â”€ Pods can communicate with any pod           â”‚
â”‚        on any node without NAT                     â”‚
â”‚                                                    â”‚
â”‚  2. Pod-to-Service Communication                   â”‚
â”‚     â””â”€ Service provides stable endpoint            â”‚
â”‚        for pod group                               â”‚
â”‚                                                    â”‚
â”‚  3. External-to-Service Communication              â”‚
â”‚     â””â”€ Ingress/LoadBalancer/NodePort               â”‚
â”‚        expose services externally                  â”‚
â”‚                                                    â”‚
â”‚  4. Network Policies                               â”‚
â”‚     â””â”€ Control traffic between pods                â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Service Discovery

**DNS in Kubernetes:**

```
Service DNS Names:

1. Full DNS Name:
   <service-name>.<namespace>.svc.cluster.local

2. Short DNS Name (same namespace):
   <service-name>

3. Headless Service (StatefulSet):
   <pod-name>.<service-name>.<namespace>.svc.cluster.local

Example:
Service: web-service in default namespace
DNS: web-service.default.svc.cluster.local
Or just: web-service (from default namespace)
```

## Network Policies

**NetworkPolicy** = Control pod-to-pod communication

````yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web
spec:
  podSelector:
    matchLabels:
      app: web
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
````

---

# ğŸ’¾ PART 5: Storage

## Storage Types

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Kubernetes Storage Options                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ 1. EmptyDir                                         â”‚
â”‚    â”œâ”€ Created when pod starts                       â”‚
â”‚    â”œâ”€ Deleted when pod stops                        â”‚
â”‚    â””â”€ Use: Temporary data, cache                    â”‚
â”‚                                                     â”‚
â”‚ 2. HostPath                                         â”‚
â”‚    â”œâ”€ Mount host directory into pod                 â”‚
â”‚    â”œâ”€ Data persists after pod dies                  â”‚
â”‚    â””â”€ Use: Development, node access                 â”‚
â”‚                                                     â”‚
â”‚ 3. PersistentVolume (PV)                            â”‚
â”‚    â”œâ”€ Cluster-wide storage resource                 â”‚
â”‚    â”œâ”€ Created by admin                              â”‚
â”‚    â””â”€ Use: Databases, caches                        â”‚
â”‚                                                     â”‚
â”‚ 4. PersistentVolumeClaim (PVC)                      â”‚
â”‚    â”œâ”€ Request for storage                           â”‚
â”‚    â”œâ”€ Binds to PV                                   â”‚
â”‚    â””â”€ Use: User-level storage requests              â”‚
â”‚                                                     â”‚
â”‚ 5. StorageClass                                     â”‚
â”‚    â”œâ”€ Dynamic PV provisioning                       â”‚
â”‚    â”œâ”€ Cloud provider integration                    â”‚
â”‚    â””â”€ Use: AWS EBS, GCP PD, Azure Disk              â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### EmptyDir Example

````yaml
apiVersion: v1
kind: Pod
metadata:
  name: temp-pod
spec:
  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: temp
      mountPath: /tmp/data
  volumes:
  - name: temp
    emptyDir: {}
````

### HostPath Example

````yaml
apiVersion: v1
kind: Pod
metadata:
  name: host-pod
spec:
  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: host-data
      mountPath: /data
  volumes:
  - name: host-data
    hostPath:
      path: /var/lib/data
      type: Directory
````

### PersistentVolume + PVC Example

````yaml
# 1. Create PersistentVolume
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-data
spec:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/pv
---
# 2. Create PersistentVolumeClaim
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-data
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
# 3. Use in Pod
apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - name: app
    image: myapp:1.0
    volumeMounts:
    - name: storage
      mountPath: /data
  volumes:
  - name: storage
    persistentVolumeClaim:
      claimName: pvc-data
````

### StorageClass (Dynamic Provisioning)

````yaml
# 1. Create StorageClass
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
allowVolumeExpansion: true
---
# 2. PVC uses StorageClass
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: dynamic-pvc
spec:
  storageClassName: fast-ssd
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
# 3. Pod uses PVC
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: app
        image: myapp:1.0
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: dynamic-pvc
````

---

# ğŸš€ PART 6: Advanced Kubernetes Concepts

## 1. Resource Management

### Resource Requests & Limits

````yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app
spec:
  template:
    spec:
      containers:
      - name: app
        image: myapp:1.0
        resources:
          # Minimum guaranteed resources
          requests:
            memory: "256Mi"
            cpu: "250m"              # 0.25 CPU cores
          # Maximum allowed resources
          limits:
            memory: "512Mi"
            cpu: "500m"              # 0.5 CPU cores
        # Pod Quality of Service (QoS)
        # Guaranteed: requests == limits
        # Burstable: requests < limits
        # BestEffort: no requests/limits
````

**How CPU & Memory work:**

```
CPU Units:
â”œâ”€ 1000m = 1 core
â”œâ”€ 500m = 0.5 core
â”œâ”€ 100m = 0.1 core
â””â”€ Example: "250m" = 0.25 core

Memory Units:
â”œâ”€ Ki = Kibibyte
â”œâ”€ Mi = Mebibyte (1024 * 1024 bytes)
â”œâ”€ Gi = Gibibyte (1024 * 1024 * 1024 bytes)
â””â”€ Example: "256Mi" â‰ˆ 256 MB

Requests: What pod needs to be scheduled
Limits: Maximum it can use
```

## 2. Horizontal Pod Autoscaler (HPA)

**HPA** = Automatically scale pods based on metrics

````yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70    # Scale up if > 70% CPU
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80    # Scale up if > 80% memory
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50                 # Scale down by 50% max
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100               # Scale up by 100% max
        periodSeconds: 30
````

**How HPA works:**

```
Step 1: Monitor metrics
        â†“
Step 2: Calculate desired replicas
        â”œâ”€ If CPU > 70% â†’ increase
        â”œâ”€ If CPU < 70% â†’ decrease
        â””â”€ If memory > 80% â†’ increase
        â†“
Step 3: Scale deployment
        â”œâ”€ Add/remove pods
        â””â”€ Gradual (respects behavior policies)
```

## 3. Vertical Pod Autoscaler (VPA)

**VPA** = Automatically adjust resource requests/limits

````yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: app-vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: myapp
  updatePolicy:
    updateMode: "Auto"            # Modes: Off, Initial, Recreate, Auto
  resourcePolicy:
    containerPolicies:
    - containerName: app
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 2
        memory: 1Gi
````

## 4. Pod Disruption Budget (PDB)

**PDB** = Ensure minimum availability during disruptions

````yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: app-pdb
spec:
  minAvailable: 2              # Keep min 2 pods running
  selector:
    matchLabels:
      app: myapp
---
# Alternative: maxUnavailable
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: app-pdb
spec:
  maxUnavailable: 1            # Allow max 1 pod down
  selector:
    matchLabels:
      app: myapp
````

## 5. Role-Based Access Control (RBAC)

**RBAC** = Control who can do what in cluster

````yaml
# 1. Create Role (permissions)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: developer
rules:
- apiGroups: [""]
  resources: ["pods", "services"]
  verbs: ["get", "list", "create", "update", "delete"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "create", "update"]
---
# 2. Create ServiceAccount (identity)
apiVersion: v1
kind: ServiceAccount
metadata:
  name: dev-user
---
# 3. Bind Role to ServiceAccount
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: dev-user-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: developer
subjects:
- kind: ServiceAccount
  name: dev-user
  namespace: default
````

## 6. Network Policies (Advanced)

````yaml
# Deny all ingress
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny
spec:
  podSelector: {}
  policyTypes:
  - Ingress
---
# Allow specific ingress
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    - namespaceSelector:
        matchLabels:
          name: frontend-ns
    ports:
    - protocol: TCP
      port: 8080
````

## 7. Custom Resources (CRDs)

**CRD** = Define custom Kubernetes objects

````yaml
# 1. Define the CRD
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: websites.example.com
spec:
  group: example.com
  names:
    kind: Website
    plural: websites
  scope: Namespaced
  versions:
  - name: v1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              domain:
                type: string
              replicas:
                type: integer
---
# 2. Use the CRD
apiVersion: example.com/v1
kind: Website
metadata:
  name: mywebsite
spec:
  domain: mywebsite.com
  replicas: 3
````

## 8. Operators (Advanced Automation)

**Operator** = Custom controller managing CRDs

```
Operator Pattern:
â””â”€ Combines CRD + Controller
   â”œâ”€ CRD: Defines custom resource
   â”œâ”€ Controller: Watches and manages resources
   â””â”€ Reconciliation loop: Makes desired state = actual state

Example: Database Operator
â”œâ”€ CRD: Database resource
â”œâ”€ Controller: Creates/updates DB
â””â”€ Watches for changes

Popular Operators:
â”œâ”€ Prometheus Operator (monitoring)
â”œâ”€ etcd Operator (database)
â”œâ”€ PostgreSQL Operator (database)
â”œâ”€ MySQL Operator (database)
â””â”€ Kafka Operator (messaging)
```

## 9. Helm (Package Manager)

**Helm** = Package manager for Kubernetes

````bash
# Install Helm
brew install helm

# Add repository
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update

# Search chart
helm search repo nginx

# Install chart
helm install my-release bitnami/nginx

# List releases
helm list

# Upgrade release
helm upgrade my-release bitnami/nginx --values values.yaml

# Rollback
helm rollback my-release 1

# Uninstall
helm uninstall my-release

# Create your own chart
helm create mychart

# Package chart
helm package mychart/

# Install from local
helm install my-release ./mychart/
````

**Helm Chart Structure:**

```
mychart/
â”œâ”€ Chart.yaml              (Chart metadata)
â”œâ”€ values.yaml             (Default values)
â”œâ”€ values-prod.yaml        (Production values)
â”œâ”€ templates/
â”‚  â”œâ”€ deployment.yaml      (Deployment template)
â”‚  â”œâ”€ service.yaml         (Service template)
â”‚  â”œâ”€ configmap.yaml       (ConfigMap template)
â”‚  â”œâ”€ secret.yaml          (Secret template)
â”‚  â””â”€ _helpers.tpl         (Helper functions)
â”œâ”€ charts/                 (Dependencies)
â””â”€ README.md
```

## 10. Kustomize (Configuration Management)

**Kustomize** = Template-free customization

````bash
# Create kustomization
kustomize create --autodetect

# Build
kustomize build ./overlay/prod | kubectl apply -f -

# Or kubectl built-in
kubectl apply -k ./overlay/prod
````

**Kustomization Structure:**

```
base/
â”œâ”€ kustomization.yaml
â”œâ”€ deployment.yaml
â””â”€ service.yaml

overlay/
â”œâ”€ dev/
â”‚  â”œâ”€ kustomization.yaml (patch for dev)
â”‚  â””â”€ deployment-patch.yaml
â””â”€ prod/
   â”œâ”€ kustomization.yaml (patch for prod)
   â””â”€ deployment-patch.yaml
```

---

# ğŸ¯ PART 7: Best Practices

## 1. Resource Management

```yaml
âœ… GOOD:
spec:
  containers:
  - name: app
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"

âŒ BAD:
spec:
  containers:
  - name: app
    # No resource limits
    # Pod could consume all cluster resources
```

## 2. Health Checks

```yaml
âœ… GOOD:
spec:
  containers:
  - name: app
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5

âŒ BAD:
spec:
  containers:
  - name: app
    # No health checks
    # Failed pods stay running
```

## 3. Rolling Updates

```yaml
âœ… GOOD:
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1           # One extra pod during update
      maxUnavailable: 0     # Zero pods unavailable
  minReadySeconds: 30       # Wait 30s before considering ready

âŒ BAD:
spec:
  strategy:
    type: Recreate         # Kill all, start all (downtime!)
```

## 4. Security

```yaml
âœ… GOOD:
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsReadOnlyRootFilesystem: true
  containers:
  - name: app
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL

âŒ BAD:
spec:
  containers:
  - name: app
    securityContext:
      runAsUser: 0          # Running as root!
      privileged: true      # Privileged container!
```

## 5. Image Best Practices

```yaml
âœ… GOOD:
containers:
- name: app
  image: myregistry/myapp:v1.2.3    # Specific tag
  imagePullPolicy: IfNotPresent     # Don't pull every time

âŒ BAD:
containers:
- name: app
  image: myapp                      # No registry, no tag
  image: myapp:latest               # Latest tag (mutable)
```

## 6. Namespaces & Organization

```yaml
âœ… GOOD:
â””â”€ Kubernetes Cluster
   â”œâ”€ Namespace: production
   â”‚  â”œâ”€ Deployment: app
   â”‚  â”œâ”€ Service: app
   â”‚  â””â”€ PVC: app-data
   â”œâ”€ Namespace: staging
   â”‚  â”œâ”€ Deployment: app
   â”‚  â””â”€ Service: app
   â””â”€ Namespace: monitoring
      â”œâ”€ Prometheus
      â””â”€ Grafana

âŒ BAD:
â””â”€ Kubernetes Cluster
   â””â”€ Namespace: default
      â”œâ”€ Everything mixed together
      â””â”€ Hard to manage
```

## 7. Logging & Monitoring

```yaml
âœ… GOOD:
containers:
- name: app
  env:
  - name: LOG_LEVEL
    value: INFO
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"

# Separate monitoring setup:
- Prometheus for metrics
- Grafana for visualization
- ELK/Loki for logs
- Jaeger for tracing

âŒ BAD:
# No monitoring setup
# Application logs nowhere
# No visibility into cluster
```

## 8. GitOps Workflow

```yaml
âœ… GOOD:
â”œâ”€ Git Repository
â”‚  â”œâ”€ k8s/base/
â”‚  â”‚  â”œâ”€ deployment.yaml
â”‚  â”‚  â”œâ”€ service.yaml
â”‚  â”‚  â””â”€ kustomization.yaml
â”‚  â”œâ”€ k8s/overlay/prod/
â”‚  â”‚  â”œâ”€ kustomization.yaml
â”‚  â”‚  â””â”€ kustomization-patch.yaml
â”‚  â””â”€ .github/workflows/
â”‚     â””â”€ deploy.yml (ArgoCD/Flux)
â”‚
â””â”€ CD Pipeline
   â”œâ”€ Commit to Git
   â”œâ”€ Pipeline checks manifests
   â”œâ”€ Apply to cluster
   â””â”€ ArgoCD syncs desired state

âŒ BAD:
# Manual kubectl apply
# No version control
# No audit trail
# No rollback capability
```

---

# ğŸ“š Complete Kubernetes Cheat Sheet

## kubectl Commands

```bash
# Cluster Info
kubectl cluster-info
kubectl get nodes
kubectl describe node <node-name>

# Pods
kubectl get pods
kubectl get pods -o wide
kubectl get pods --all-namespaces
kubectl describe pod <pod-name>
kubectl logs <pod-name>
kubectl logs <pod-name> -f              # Follow logs
kubectl logs <pod-name> -c <container>  # Specific container
kubectl exec -it <pod-name> -- bash     # Execute command

# Deployments
kubectl get deployments
kubectl create deployment <name> --image=<image>
kubectl scale deployment <name> --replicas=3
kubectl set image deployment/<name> <container>=<image>:<tag>
kubectl rollout history deployment/<name>
kubectl rollout undo deployment/<name>
kubectl rollout status deployment/<name>

# Services
kubectl get svc
kubectl expose deployment <name> --type=NodePort --port=80 --target-port=8080
kubectl port-forward svc/<name> 8080:80

# ConfigMap & Secrets
kubectl create configmap <name> --from-literal=KEY=VALUE
kubectl create secret generic <name> --from-literal=KEY=VALUE
kubectl get configmap
kubectl get secret

# Namespaces
kubectl create namespace <name>
kubectl get namespaces
kubectl config set-context --current --namespace=<namespace>

# Apply YAML
kubectl apply -f deployment.yaml
kubectl apply -f . -R                    # Apply directory recursively
kubectl delete -f deployment.yaml
kubectl delete pod <pod-name>

# Other
kubectl get all                          # All resources
kubectl describe <resource> <name>
kubectl edit <resource> <name>
kubectl patch <resource> <name> -p '{"spec":{"replicas":3}}'
kubectl top nodes                        # Resource usage
kubectl top pods
```

---

# ğŸ“ Learning Path

```
Week 1-2: Fundamentals
â”œâ”€ Install Minikube/Docker Desktop
â”œâ”€ Learn kubectl basics
â”œâ”€ Understand Pods, Deployments, Services
â””â”€ Deploy first application

Week 3-4: Core Concepts
â”œâ”€ ConfigMaps & Secrets
â”œâ”€ Storage (PVC, PV)
â”œâ”€ Namespaces
â”œâ”€ Services & Networking
â””â”€ Ingress

Week 5-6: Advanced
â”œâ”€ StatefulSets & DaemonSets
â”œâ”€ RBAC & Security
â”œâ”€ Resource Management
â”œâ”€ Monitoring & Logging
â””â”€ Helm

Week 7-8: Production
â”œâ”€ Production deployment tools (kops, kubeadm)
â”œâ”€ High Availability
â”œâ”€ Disaster Recovery
â”œâ”€ GitOps
â””â”€ Best Practices
```

---

# ğŸ”— Resources

```
Official Kubernetes:
â”œâ”€ Kubernetes.io (official docs)
â”œâ”€ Play with Kubernetes (online)
â””â”€ Kubernetes Academy (courses)

Tools:
â”œâ”€ kubectl cheatsheet
â”œâ”€ Helm Hub (charts)
â”œâ”€ Kustomize documentation
â””â”€ CNCF Landscape

Learning:
â”œâ”€ Linux Academy
â”œâ”€ A Cloud Guru
â”œâ”€ Udemy Kubernetes courses
â”œâ”€ YouTube (KodeKloud, etc.)
â””â”€ Kubernetes by Example
```

---

## ğŸ‰ Summary

```
Kubernetes Deployment Tools at a Glance:

kind:     Fast, lightweight, testing
Minikube: Easy, local development
kops:     Production AWS clusters
kubeadm:  Manual, any infrastructure

Kubernetes Objects Hierarchy:

Cluster
â”œâ”€ Namespace
â”‚  â”œâ”€ Deployment
â”‚  â”‚  â””â”€ ReplicaSet
â”‚  â”‚     â””â”€ Pod
â”‚  â”‚        â”œâ”€ Container
â”‚  â”‚        â””â”€ Volume
â”‚  â”œâ”€ Service (network endpoint)
â”‚  â”œâ”€ Ingress (HTTP routing)
â”‚  â”œâ”€ ConfigMap (config)
â”‚  â”œâ”€ Secret (sensitive data)
â”‚  â”œâ”€ PersistentVolume (storage)
â”‚  â””â”€ PersistentVolumeClaim (storage request)

Key Concepts:

âœ… Declarative (describe desired state)
âœ… Self-healing (restarts failed containers)
âœ… Scalable (horizontal & vertical)
âœ… Flexible networking (service discovery)
âœ… Storage abstraction (multiple backends)
âœ… Advanced features (operators, CRDs)
```

---

**Now you have a complete Kubernetes guide from beginner to advanced!** ğŸš€

#Kubernetes #DevOps #Containers #Orchestration #CloudNative